{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Guided-Capstone-Step-4---Pre-processing-and-Training-Data-Development\" data-toc-modified-id=\"Guided-Capstone-Step-4---Pre-processing-and-Training-Data-Development-0\"><span class=\"toc-item-num\">0&nbsp;&nbsp;</span>Guided Capstone Step 4 - Pre-processing and Training Data Development</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#The-Data-Science-Method\" data-toc-modified-id=\"The-Data-Science-Method-0.0.1\"><span class=\"toc-item-num\">0.0.1&nbsp;&nbsp;</span><strong>The Data Science Method</strong></a></span></li></ul></li><li><span><a href=\"#Create-dummy-features-for-categorical-variables\" data-toc-modified-id=\"Create-dummy-features-for-categorical-variables-0.1\"><span class=\"toc-item-num\">0.1&nbsp;&nbsp;</span>Create dummy features for categorical variables</a></span></li><li><span><a href=\"#Standardize-the-magnitude-of-numeric-features\" data-toc-modified-id=\"Standardize-the-magnitude-of-numeric-features-0.2\"><span class=\"toc-item-num\">0.2&nbsp;&nbsp;</span>Standardize the magnitude of numeric features</a></span></li><li><span><a href=\"#Split-into-training-and-testing-datasets\" data-toc-modified-id=\"Split-into-training-and-testing-datasets-0.3\"><span class=\"toc-item-num\">0.3&nbsp;&nbsp;</span>Split into training and testing datasets</a></span></li></ul></li><li><span><a href=\"#Guided-Capstone-Step-5---Modeling\" data-toc-modified-id=\"Guided-Capstone-Step-5---Modeling-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Guided Capstone Step 5 - Modeling</a></span><ul class=\"toc-item\"><li><span><a href=\"#Fit-Models-with-Training-Data-Set\" data-toc-modified-id=\"Fit-Models-with-Training-Data-Set-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Fit Models with Training Data Set</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Model-1\" data-toc-modified-id=\"Model-1-1.1.0.1\"><span class=\"toc-item-num\">1.1.0.1&nbsp;&nbsp;</span>Model 1</a></span></li></ul></li></ul></li><li><span><a href=\"#Review-Model-Outcomes-—-Iterate-over-additional-models-as-needed.\" data-toc-modified-id=\"Review-Model-Outcomes-—-Iterate-over-additional-models-as-needed.-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Review Model Outcomes — Iterate over additional models as needed.</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Model-2\" data-toc-modified-id=\"Model-2-1.2.0.1\"><span class=\"toc-item-num\">1.2.0.1&nbsp;&nbsp;</span>Model 2</a></span></li><li><span><a href=\"#Model-3\" data-toc-modified-id=\"Model-3-1.2.0.2\"><span class=\"toc-item-num\">1.2.0.2&nbsp;&nbsp;</span>Model 3</a></span></li></ul></li></ul></li><li><span><a href=\"#Identify-the-Final-Model\" data-toc-modified-id=\"Identify-the-Final-Model-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Identify the Final Model</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cf5CmXQCZyF1"
   },
   "source": [
    "# Guided Capstone Step 4 - Pre-processing and Training Data Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JbZXsVevfr9M"
   },
   "source": [
    "### **The Data Science Method**  \n",
    "\n",
    "\n",
    "1.   Problem Identification \n",
    "\n",
    "2.   Data Wrangling \n",
    "  \n",
    "3.   Exploratory Data Analysis \n",
    " \n",
    "4.   **Pre-processing and Training Data Development**\n",
    "\n",
    "5.  Modeling\n",
    "  * Fit Models with Training Data Set\n",
    "  * Review Model Outcomes — Iterate over additional models as needed.\n",
    "  * Identify the Final Model\n",
    "\n",
    "6.   Documentation\n",
    "  * Review the Results\n",
    "  * Present and share your findings - storytelling\n",
    "  * Finalize Code \n",
    "  * Finalize Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GyZga0DpAnq7"
   },
   "source": [
    "In this step of the guided capstone, you'll revisit some of the steps you completed to solve questions in step 4. Revisiting these steps will help you get additional practice completing this kind of work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K8xfkAqqZyF2"
   },
   "source": [
    "**<font color='teal'> Start by loading the necessary packages, as you've done in the previous steps. Print out your current working directory to confirm that you are in the correct project directory. </font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ry6WPL5eZyF3"
   },
   "outputs": [],
   "source": [
    "#load python packages\n",
    "import os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "630T-ogRZyF8"
   },
   "source": [
    "**<font color='teal'>  Load the csv file you created in step 3. Remember, it should be saved inside your data subfolder. Print the first five rows.</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dMNbk0u3ZyF9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            Name       state  summit_elev  vertical_drop  \\\n",
      "0                 Alyeska Resort      Alaska         3939           2500   \n",
      "1               Hilltop Ski Area      Alaska         2090            294   \n",
      "2               Arizona Snowbowl     Arizona        11500           2300   \n",
      "3            Sunrise Park Resort     Arizona        11100           1800   \n",
      "4  Yosemite Ski & Snowboard Area  California         7800            600   \n",
      "\n",
      "   trams  fastEight  fastSixes  fastQuads  quad  triple  ...  \\\n",
      "0      1        0.0          0          2     2       0  ...   \n",
      "1      0        0.0          0          0     0       1  ...   \n",
      "2      0        0.0          1          0     2       2  ...   \n",
      "3      0        0.0          0          1     2       3  ...   \n",
      "4      0        0.0          0          0     0       1  ...   \n",
      "\n",
      "   SkiableTerrain_ac  Snow Making_ac  daysOpenLastYear  yearsOpen  \\\n",
      "0             1610.0      113.000000             150.0       60.0   \n",
      "1               30.0       30.000000             150.0       36.0   \n",
      "2              777.0      104.000000             122.0       81.0   \n",
      "3              800.0       80.000000             115.0       49.0   \n",
      "4               88.0      174.873239             110.0       84.0   \n",
      "\n",
      "   averageSnowfall  AdultWeekday  AdultWeekend  projectedDaysOpen  \\\n",
      "0            669.0          65.0          85.0              150.0   \n",
      "1             69.0          30.0          34.0              152.0   \n",
      "2            260.0          89.0          89.0              122.0   \n",
      "3            250.0          74.0          78.0              104.0   \n",
      "4            300.0          47.0          47.0              107.0   \n",
      "\n",
      "   NightSkiing_ac  kmean_cluster  \n",
      "0           550.0              0  \n",
      "1            30.0              2  \n",
      "2             0.0              1  \n",
      "3            80.0              1  \n",
      "4             0.0              1  \n",
      "\n",
      "[5 rows x 26 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 290 entries, 0 to 289\n",
      "Data columns (total 26 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Name               290 non-null    object \n",
      " 1   state              290 non-null    object \n",
      " 2   summit_elev        290 non-null    int64  \n",
      " 3   vertical_drop      290 non-null    int64  \n",
      " 4   trams              290 non-null    int64  \n",
      " 5   fastEight          290 non-null    float64\n",
      " 6   fastSixes          290 non-null    int64  \n",
      " 7   fastQuads          290 non-null    int64  \n",
      " 8   quad               290 non-null    int64  \n",
      " 9   triple             290 non-null    int64  \n",
      " 10  double             290 non-null    int64  \n",
      " 11  surface            290 non-null    int64  \n",
      " 12  total_chairs       290 non-null    int64  \n",
      " 13  Runs               290 non-null    float64\n",
      " 14  TerrainParks       290 non-null    float64\n",
      " 15  LongestRun_mi      290 non-null    float64\n",
      " 16  SkiableTerrain_ac  290 non-null    float64\n",
      " 17  Snow Making_ac     290 non-null    float64\n",
      " 18  daysOpenLastYear   290 non-null    float64\n",
      " 19  yearsOpen          290 non-null    float64\n",
      " 20  averageSnowfall    290 non-null    float64\n",
      " 21  AdultWeekday       290 non-null    float64\n",
      " 22  AdultWeekend       290 non-null    float64\n",
      " 23  projectedDaysOpen  290 non-null    float64\n",
      " 24  NightSkiing_ac     290 non-null    float64\n",
      " 25  kmean_cluster      290 non-null    int64  \n",
      "dtypes: float64(13), int64(11), object(2)\n",
      "memory usage: 59.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/step3_output.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zkBHf9smZyGB"
   },
   "source": [
    "## Create dummy features for categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vWKHm0NhAnrJ"
   },
   "source": [
    "**<font color='teal'> Create dummy variables for `State`. Add the dummies back to the dataframe and remove the original column for `State`. </font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove state column and create dummies variables\n",
    "df = pd.concat([df.drop('state', axis=1), pd.get_dummies(df.state)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HnDVhE1-ZyGF"
   },
   "source": [
    "## Standardize the magnitude of numeric features\n",
    "\n",
    "**<font color='teal'> Using sklearn preprocessing, standardize the scale of the features of the dataframe except the name of the resort, which you don't need in the dataframe for modeling so it can be droppped here as well. You should  hold out your response variable(s) so that you can have their true values available for model performance review. Let's set `AdultWeekend` to the y variable as your response for scaling and modeling. Later, you will go back and consider the `AdultWeekday`, `dayOpenLastYear`, and `projectedDaysOpen`. For now leave them in the development dataframe. </font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove column Name from the dataframe\n",
    "df.drop('Name', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign Y to AdultWeekend and the rest of the dataframe to X\n",
    "Y = df['AdultWeekend']\n",
    "X = df.drop('AdultWeekend', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the scale of each features in X\n",
    "# scaler = StandardScaler().fit(X)\n",
    "# X_scaled=scaler.transform(X)\n",
    "\n",
    "# Using scale() scales the entire dataframe while the StandardScaler() scales each column. \n",
    "X_scaled = scale(X, axis=0, with_mean=True, with_std=True, copy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GAT8h4_mZyGK"
   },
   "source": [
    "## Split into training and testing datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6rdS8EGeAnrW"
   },
   "source": [
    "**<font color='teal'> Using sklearn model selectionm import train_test_split, and create a 75/25 split with the y = `AdultWeekend`. You will start by using the adult weekend ticket price as your response variable for modeling.</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BSkPut0gguds"
   },
   "outputs": [],
   "source": [
    "# Create a 75/25 train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, Y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UayqbwkWAnra"
   },
   "source": [
    "Here, you'll start the actual modeling work. First let's fit a multiple linear regression model to predict the `AdultWeekend` price."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guided Capstone Step 5 - Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've cleaned and prepared the datasets, so now it's time to get into the most exciting part of this process: modeling! In this exercise, you will build three different models and compare each model's performance. In the end, you will choose the best model for proving insights to Big Mountain management.  \n",
    "\n",
    "1.   Problem Identification \n",
    "\n",
    "2.   Data Wrangling \n",
    "  \n",
    "3.   Exploratory Data Analysis \n",
    " \n",
    "4.   Pre-processing and Training Data Development\n",
    "\n",
    "5.   **Modeling**\n",
    "  * Fit Models with Training Data Set\n",
    "  * Review Model Outcomes — Iterate over additional models as needed.\n",
    "  * Identify the Final Model\n",
    "\n",
    "6.   Documentation\n",
    "  * Review the Results\n",
    "  * Present and share your findings - storytelling\n",
    "  * Finalize Code \n",
    "  * Finalize Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D_wfsP_-Anra"
   },
   "source": [
    "## Fit Models with Training Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CoI8S5SwAnrc"
   },
   "source": [
    "**<font color='teal'> Using sklearn, fit the model on your training dataset.</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P_GFr8sRAnrd"
   },
   "source": [
    "#### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fW6K7uOPAnre"
   },
   "outputs": [],
   "source": [
    "#all first model set\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import explained_variance_score,mean_absolute_error\n",
    "lm = linear_model.LinearRegression()\n",
    "model = lm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1fHqz9-WAnrg"
   },
   "source": [
    "**<font color='teal'> Predict on the testing dataset and score the model performance with the y_test set and the y-pred values. The explained variance is a measure of the variation explained by the model. This is also known as the R-squared value. </font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a prediction y_pred\n",
    "y_pred = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nIo01lFEAnrh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance Score (R-squared): -305154320124414550605824.00\n",
      "Mean Absolute Error: 2586201762840.33\n"
     ]
    }
   ],
   "source": [
    "print('Explained Variance Score (R-squared): %.2f'\n",
    "      % explained_variance_score(y_test, y_pred))\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print('Mean Absolute Error: %.2f'\n",
    "      % mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N4YS0WE2Anrk"
   },
   "source": [
    "## Review Model Outcomes — Iterate over additional models as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HSh9sGIYAnrk"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "651009409326.9098"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Intercept value from the linear model\n",
    "lm.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NWJcOuSdAnrr"
   },
   "source": [
    "**<font color='teal'> Print the intercept value from the linear model. </font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3WzWejn6Anrt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Coefficient\n",
      "New York           9.992233e+12\n",
      "Michigan           9.293273e+12\n",
      "California         7.391708e+12\n",
      "Pennsylvania       7.391708e+12\n",
      "Wisconsin          6.968688e+12\n",
      "New Hampshire      6.968688e+12\n",
      "Colorado           6.744622e+12\n",
      "Vermont            6.511043e+12\n",
      "Minnesota          6.266890e+12\n",
      "Montana            6.010872e+12\n",
      "Massachusetts      6.010872e+12\n",
      "Idaho              5.741403e+12\n",
      "Washington         5.741403e+12\n",
      "Wyoming            5.153575e+12\n",
      "Utah               5.153575e+12\n",
      "Maine              5.153575e+12\n",
      "New Mexico         4.829268e+12\n",
      "Oregon             4.829268e+12\n",
      "Ohio               4.095873e+12\n",
      "Connecticut        4.095873e+12\n",
      "North Carolina     4.095873e+12\n",
      "Virginia           3.669882e+12\n",
      "West Virginia      3.669882e+12\n",
      "Illinois           3.183762e+12\n",
      "Iowa               3.183762e+12\n",
      "Indiana            2.604056e+12\n",
      "Arizona            2.604056e+12\n",
      "New Jersey         2.604056e+12\n",
      "Nevada             2.604056e+12\n",
      "Alaska             2.604056e+12\n",
      "Tennessee          1.844539e+12\n",
      "total_chairs       1.429181e+12\n",
      "surface            5.235764e+11\n",
      "double             5.123622e+11\n",
      "fastQuads          4.918306e+11\n",
      "triple             4.474872e+11\n",
      "quad               3.560851e+11\n",
      "fastSixes          1.621749e+11\n",
      "trams              1.231188e+11\n",
      "fastEight          1.624450e+10\n",
      "Maryland           7.995049e+07\n",
      "Missouri           2.186097e+06\n",
      "AdultWeekday       1.295216e+01\n",
      "vertical_drop      2.659253e+00\n",
      "SkiableTerrain_ac  1.578461e+00\n",
      "projectedDaysOpen  1.341675e+00\n",
      "NightSkiing_ac     1.253044e+00\n",
      "summit_elev        8.968498e-01\n",
      "averageSnowfall    8.562012e-01\n",
      "kmean_cluster      7.463989e-01\n",
      "daysOpenLastYear   5.881500e-01\n",
      "Snow Making_ac     4.957352e-01\n",
      "Rhode Island       4.501724e-01\n",
      "TerrainParks       4.403687e-01\n",
      "LongestRun_mi      3.795471e-01\n",
      "Runs               3.291702e-01\n",
      "South Dakota       1.089478e-01\n",
      "yearsOpen          7.100677e-02\n"
     ]
    }
   ],
   "source": [
    "# Sort and print coeff\n",
    "coeff_df = pd.DataFrame(abs(lm.coef_), X.columns, columns=['Coefficient'])\n",
    "print(coeff_df.sort_values(by=['Coefficient'], ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "edajrenAAnrv"
   },
   "source": [
    "**<font color='teal'> The intercept is the mean `AdultWeekend` price for all the resorts given the other characteristics. The addition or subtraction of each of the coefficient values in the regression are numeric adjustments applied to the intercept to provide a particular observation's value for the `AdultWeekend` resulting value. Also, because you took the time to scale your x values in the training data, you can compare each of the coefficients for the features to determine the feature's importance. Print the coefficient values from the linear model and sort in descending order to identify the top ten most important features.</font>** \n",
    "\n",
    "Hint: make sure to review the absolute value of the coefficients, because the adjustment may be positive or negative, but what you are looking for is the magnitude of impact on your response variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass X_train & X_test as DataFrame and add columns names\n",
    "X_train_df = pd.DataFrame(X_train, columns=X.columns)\n",
    "X_test_df = pd.DataFrame(X_test, columns=X.columns)\n",
    "\n",
    "\n",
    "# Drop the states columns\n",
    "X_train = X_train_df.drop(X_train_df.iloc[:,23:], axis = 1, inplace = False)\n",
    "X_test = X_test_df.drop(X_test_df.iloc[:,23:], axis = 1, inplace = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result as not as good as model one as the location of the resort plays a big importance on the price."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BpdALMoAAnry"
   },
   "source": [
    "**<font color='teal'>You should see that the top ten important features are different states. However, the state is not something the managers at the Big Mountain Resort can do anything about. Given that you care more about actionable traits associated with ticket pricing, rebuild the model without the state features and compare the results. </font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-mHYA1BzAnrz"
   },
   "source": [
    "#### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pz1YXAdiAnr0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance Score (R-squared): 0.75\n",
      "Mean Absolute Error: 6.30\n"
     ]
    }
   ],
   "source": [
    "#model2\n",
    "lm2 = linear_model.LinearRegression()\n",
    "model2 = lm2.fit(X_train,y_train)\n",
    "\n",
    "# Create a prediction y_pred\n",
    "y_pred2 = lm2.predict(X_test)\n",
    "\n",
    "print('Explained Variance Score (R-squared): %.2f'\n",
    "      % explained_variance_score(y_test, y_pred2))\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print('Mean Absolute Error: %.2f'\n",
    "      % mean_absolute_error(y_test, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nM1EGf16Anr2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Coefficient\n",
      "AdultWeekday         13.059204\n",
      "quad                  1.900765\n",
      "summit_elev           1.673705\n",
      "kmean_cluster         1.634898\n",
      "SkiableTerrain_ac     1.389582\n",
      "vertical_drop         1.319085\n",
      "trams                 1.272987\n",
      "daysOpenLastYear      1.228319\n",
      "projectedDaysOpen     1.193344\n",
      "NightSkiing_ac        1.068156\n",
      "total_chairs          0.861155\n",
      "averageSnowfall       0.861034\n",
      "fastQuads             0.843511\n",
      "triple                0.785456\n",
      "LongestRun_mi         0.605727\n",
      "surface               0.544277\n",
      "double                0.352227\n",
      "fastSixes             0.332506\n",
      "fastEight             0.315490\n",
      "Snow Making_ac        0.217392\n",
      "yearsOpen             0.215653\n",
      "Runs                  0.040949\n",
      "TerrainParks          0.018366\n"
     ]
    }
   ],
   "source": [
    "# Sort and print coeff\n",
    "coeff_df = pd.DataFrame(abs(lm2.coef_), X_test.columns, columns=['Coefficient'])\n",
    "print(coeff_df.sort_values(by=['Coefficient'], ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JWjQLr3LAnr6"
   },
   "source": [
    "**<font color='teal'> When reviewing your new model coefficients, note that `summit_elev` is now in the number two spot. From a managerial perspective, this is also difficult to change and highly correlated with `base_elev` and `vertical_drop`.  This time rebuild the model without the state features and without the `summit_elev` and without `base_elev`and compare the results. </font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RXqvcn93Anr7"
   },
   "source": [
    "#### Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6eugnDNNAnr8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance Score (R-squared): 0.73\n",
      "Mean Absolute Error: 6.61\n"
     ]
    }
   ],
   "source": [
    "# summit_elev was removed in step3 when checking high correlation between 2 features.\n",
    "# Remove base_elev\n",
    "X_train = X_train.drop(['summit_elev'], axis = 1)\n",
    "X_test = X_test.drop(['summit_elev'], axis = 1)\n",
    "\n",
    "\n",
    "#model3 \n",
    "lm3 = linear_model.LinearRegression()\n",
    "model3 = lm3.fit(X_train,y_train)\n",
    "\n",
    "# Create a prediction y_pred\n",
    "y_pred3 = lm3.predict(X_test)\n",
    "\n",
    "print('Explained Variance Score (R-squared): %.2f'\n",
    "      % explained_variance_score(y_test, y_pred3))\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print('Mean Absolute Error: %.2f'\n",
    "      % mean_absolute_error(y_test, y_pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pq0pW7G9Anr_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Coefficient\n",
      "AdultWeekday         13.006530\n",
      "quad                  1.939247\n",
      "SkiableTerrain_ac     1.843976\n",
      "averageSnowfall       1.464031\n",
      "NightSkiing_ac        1.408704\n",
      "kmean_cluster         1.343559\n",
      "trams                 1.060264\n",
      "daysOpenLastYear      0.987406\n",
      "projectedDaysOpen     0.986666\n",
      "vertical_drop         0.881814\n",
      "total_chairs          0.850489\n",
      "LongestRun_mi         0.818587\n",
      "fastQuads             0.653341\n",
      "triple                0.597186\n",
      "Snow Making_ac        0.481213\n",
      "fastSixes             0.417003\n",
      "fastEight             0.371374\n",
      "double                0.362983\n",
      "surface               0.345001\n",
      "yearsOpen             0.289082\n",
      "Runs                  0.228152\n",
      "TerrainParks          0.178652\n"
     ]
    }
   ],
   "source": [
    "# Sort and print coeff\n",
    "coeff_df = pd.DataFrame(abs(lm3.coef_), X_test.columns, columns=['Coefficient'])\n",
    "print(coeff_df.sort_values(by=['Coefficient'], ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MJvQMns6AnsI"
   },
   "source": [
    "## Identify the Final Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LD7-3iLcAnsK"
   },
   "source": [
    "**<font color='teal'> Review the model performances in the table below and choose the best model for proving insights to Big Mountain management about what features are driving ski resort lift ticket prices. Type your choice in the final markdown cell. You will explain your selection during the next step of the guided casptone. </font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "La5S9fRPAnsK"
   },
   "source": [
    "| Model | Explained Variance| Mean Absolute Error|Features Dropped|\n",
    "| --- | --- | --- | --- |\n",
    "| Model 1. | -305154320124414550605824 |2586201762840  |-|\n",
    "| Model 2. | 0.75|6.3 |'state'|\n",
    "| Model 3. | 0.73 |6.61 |'state','summit_elev','base_elev'|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T2c-zn7TAnsL"
   },
   "source": [
    "Model Selection:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CgC0eMBrAnsM"
   },
   "source": [
    "I will choose model 2 because the performance are slightly better and even if we can not change the summit elevation of our resort, model 2 will give us a better idea of the price range for resort of the same standings."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "RtEspslPZyGY",
    "s0DokMkAZyGc",
    "2iuitnKcZyHS",
    "iAWQxougZyHW",
    "ThMTimlBZyHZ",
    "QwZ-LkjXZyHt",
    "srtXEA3N4-Y9",
    "ChVreJupZyIA",
    "zDgSSsq1ZyID",
    "I3GYKWfi5Llg",
    "pmMvrhbI-viE",
    "ZXDPkW3UZyIX",
    "Dnc_vHQLZyId",
    "daJxuJ-dZyIg",
    "mAQ-oHiPZyIn",
    "hnGOsp3mZyIp"
   ],
   "name": "GuidedCapstoneStep5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": "0",
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
