{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Guided-Capstone-Step-4---Pre-processing-and-Training-Data-Development\" data-toc-modified-id=\"Guided-Capstone-Step-4---Pre-processing-and-Training-Data-Development-0\"><span class=\"toc-item-num\">0&nbsp;&nbsp;</span>Guided Capstone Step 4 - Pre-processing and Training Data Development</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#The-Data-Science-Method\" data-toc-modified-id=\"The-Data-Science-Method-0.0.1\"><span class=\"toc-item-num\">0.0.1&nbsp;&nbsp;</span><strong>The Data Science Method</strong></a></span></li></ul></li><li><span><a href=\"#Create-dummy-features-for-categorical-variables\" data-toc-modified-id=\"Create-dummy-features-for-categorical-variables-0.1\"><span class=\"toc-item-num\">0.1&nbsp;&nbsp;</span>Create dummy features for categorical variables</a></span></li><li><span><a href=\"#Standardize-the-magnitude-of-numeric-features\" data-toc-modified-id=\"Standardize-the-magnitude-of-numeric-features-0.2\"><span class=\"toc-item-num\">0.2&nbsp;&nbsp;</span>Standardize the magnitude of numeric features</a></span></li><li><span><a href=\"#Split-into-training-and-testing-datasets\" data-toc-modified-id=\"Split-into-training-and-testing-datasets-0.3\"><span class=\"toc-item-num\">0.3&nbsp;&nbsp;</span>Split into training and testing datasets</a></span></li></ul></li><li><span><a href=\"#Guided-Capstone-Step-5---Modeling\" data-toc-modified-id=\"Guided-Capstone-Step-5---Modeling-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Guided Capstone Step 5 - Modeling</a></span><ul class=\"toc-item\"><li><span><a href=\"#Fit-Models-with-Training-Data-Set\" data-toc-modified-id=\"Fit-Models-with-Training-Data-Set-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Fit Models with Training Data Set</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Model-1\" data-toc-modified-id=\"Model-1-1.1.0.1\"><span class=\"toc-item-num\">1.1.0.1&nbsp;&nbsp;</span>Model 1</a></span></li></ul></li></ul></li><li><span><a href=\"#Review-Model-Outcomes-—-Iterate-over-additional-models-as-needed.\" data-toc-modified-id=\"Review-Model-Outcomes-—-Iterate-over-additional-models-as-needed.-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Review Model Outcomes — Iterate over additional models as needed.</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Model-2\" data-toc-modified-id=\"Model-2-1.2.0.1\"><span class=\"toc-item-num\">1.2.0.1&nbsp;&nbsp;</span>Model 2</a></span></li><li><span><a href=\"#Model-3\" data-toc-modified-id=\"Model-3-1.2.0.2\"><span class=\"toc-item-num\">1.2.0.2&nbsp;&nbsp;</span>Model 3</a></span></li></ul></li></ul></li><li><span><a href=\"#Identify-the-Final-Model\" data-toc-modified-id=\"Identify-the-Final-Model-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Identify the Final Model</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cf5CmXQCZyF1"
   },
   "source": [
    "# Guided Capstone Step 4 - Pre-processing and Training Data Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JbZXsVevfr9M"
   },
   "source": [
    "### **The Data Science Method**  \n",
    "\n",
    "\n",
    "1.   Problem Identification \n",
    "\n",
    "2.   Data Wrangling \n",
    "  \n",
    "3.   Exploratory Data Analysis \n",
    " \n",
    "4.   **Pre-processing and Training Data Development**\n",
    "\n",
    "5.  Modeling\n",
    "  * Fit Models with Training Data Set\n",
    "  * Review Model Outcomes — Iterate over additional models as needed.\n",
    "  * Identify the Final Model\n",
    "\n",
    "6.   Documentation\n",
    "  * Review the Results\n",
    "  * Present and share your findings - storytelling\n",
    "  * Finalize Code \n",
    "  * Finalize Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GyZga0DpAnq7"
   },
   "source": [
    "In this step of the guided capstone, you'll revisit some of the steps you completed to solve questions in step 4. Revisiting these steps will help you get additional practice completing this kind of work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K8xfkAqqZyF2"
   },
   "source": [
    "**<font color='teal'> Start by loading the necessary packages, as you've done in the previous steps. Print out your current working directory to confirm that you are in the correct project directory. </font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ry6WPL5eZyF3"
   },
   "outputs": [],
   "source": [
    "#load python packages\n",
    "import os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "630T-ogRZyF8"
   },
   "source": [
    "**<font color='teal'>  Load the csv file you created in step 3. Remember, it should be saved inside your data subfolder. Print the first five rows.</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dMNbk0u3ZyF9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            Name       state  vertical_drop  base_elev  trams  \\\n",
      "0                 Alyeska Resort      Alaska           2500        250      1   \n",
      "1               Hilltop Ski Area      Alaska            294       1796      0   \n",
      "2               Arizona Snowbowl     Arizona           2300       9200      0   \n",
      "3            Sunrise Park Resort     Arizona           1800       9200      0   \n",
      "4  Yosemite Ski & Snowboard Area  California            600       7200      0   \n",
      "\n",
      "   fastEight  fastSixes  fastQuads  quad  triple  ...  SkiableTerrain_ac  \\\n",
      "0        0.0          0          2     2       0  ...             1610.0   \n",
      "1        0.0          0          0     0       1  ...               30.0   \n",
      "2        0.0          1          0     2       2  ...              777.0   \n",
      "3        0.0          0          1     2       3  ...              800.0   \n",
      "4        0.0          0          0     0       1  ...               88.0   \n",
      "\n",
      "   Snow Making_ac  daysOpenLastYear  yearsOpen  averageSnowfall  AdultWeekday  \\\n",
      "0      113.000000             150.0       60.0            669.0          65.0   \n",
      "1       30.000000             150.0       36.0             69.0          30.0   \n",
      "2      104.000000             122.0       81.0            260.0          89.0   \n",
      "3       80.000000             115.0       49.0            250.0          74.0   \n",
      "4      174.873239             110.0       84.0            300.0          47.0   \n",
      "\n",
      "   AdultWeekend  projectedDaysOpen  NightSkiing_ac  kmean_cluster  \n",
      "0          85.0              150.0           550.0              0  \n",
      "1          34.0              152.0            30.0              0  \n",
      "2          89.0              122.0             0.0              1  \n",
      "3          78.0              104.0            80.0              1  \n",
      "4          47.0              107.0             0.0              1  \n",
      "\n",
      "[5 rows x 26 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 276 entries, 0 to 275\n",
      "Data columns (total 26 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Name               276 non-null    object \n",
      " 1   state              276 non-null    object \n",
      " 2   vertical_drop      276 non-null    int64  \n",
      " 3   base_elev          276 non-null    int64  \n",
      " 4   trams              276 non-null    int64  \n",
      " 5   fastEight          276 non-null    float64\n",
      " 6   fastSixes          276 non-null    int64  \n",
      " 7   fastQuads          276 non-null    int64  \n",
      " 8   quad               276 non-null    int64  \n",
      " 9   triple             276 non-null    int64  \n",
      " 10  double             276 non-null    int64  \n",
      " 11  surface            276 non-null    int64  \n",
      " 12  total_chairs       276 non-null    int64  \n",
      " 13  Runs               276 non-null    float64\n",
      " 14  TerrainParks       276 non-null    float64\n",
      " 15  LongestRun_mi      276 non-null    float64\n",
      " 16  SkiableTerrain_ac  276 non-null    float64\n",
      " 17  Snow Making_ac     276 non-null    float64\n",
      " 18  daysOpenLastYear   276 non-null    float64\n",
      " 19  yearsOpen          276 non-null    float64\n",
      " 20  averageSnowfall    276 non-null    float64\n",
      " 21  AdultWeekday       276 non-null    float64\n",
      " 22  AdultWeekend       276 non-null    float64\n",
      " 23  projectedDaysOpen  276 non-null    float64\n",
      " 24  NightSkiing_ac     276 non-null    float64\n",
      " 25  kmean_cluster      276 non-null    int64  \n",
      "dtypes: float64(13), int64(11), object(2)\n",
      "memory usage: 56.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/step3_output.csv')\n",
    "print(df.head())\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zkBHf9smZyGB"
   },
   "source": [
    "## Create dummy features for categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vWKHm0NhAnrJ"
   },
   "source": [
    "**<font color='teal'> Create dummy variables for `State`. Add the dummies back to the dataframe and remove the original column for `State`. </font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            Name  vertical_drop  base_elev  trams  fastEight  \\\n",
      "0                 Alyeska Resort           2500        250      1        0.0   \n",
      "1               Hilltop Ski Area            294       1796      0        0.0   \n",
      "2               Arizona Snowbowl           2300       9200      0        0.0   \n",
      "3            Sunrise Park Resort           1800       9200      0        0.0   \n",
      "4  Yosemite Ski & Snowboard Area            600       7200      0        0.0   \n",
      "\n",
      "   fastSixes  fastQuads  quad  triple  double  ...  Rhode Island  \\\n",
      "0          0          2     2       0       0  ...             0   \n",
      "1          0          0     0       1       0  ...             0   \n",
      "2          1          0     2       2       1  ...             0   \n",
      "3          0          1     2       3       1  ...             0   \n",
      "4          0          0     0       1       3  ...             0   \n",
      "\n",
      "   South Dakota  Tennessee  Utah  Vermont  Virginia  Washington  \\\n",
      "0             0          0     0        0         0           0   \n",
      "1             0          0     0        0         0           0   \n",
      "2             0          0     0        0         0           0   \n",
      "3             0          0     0        0         0           0   \n",
      "4             0          0     0        0         0           0   \n",
      "\n",
      "   West Virginia  Wisconsin  Wyoming  \n",
      "0              0          0        0  \n",
      "1              0          0        0  \n",
      "2              0          0        0  \n",
      "3              0          0        0  \n",
      "4              0          0        0  \n",
      "\n",
      "[5 rows x 60 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([df.drop('state', axis=1), pd.get_dummies(dfo)], axis=1)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HnDVhE1-ZyGF"
   },
   "source": [
    "## Standardize the magnitude of numeric features\n",
    "\n",
    "**<font color='teal'> Using sklearn preprocessing, standardize the scale of the features of the dataframe except the name of the resort, which you don't need in the dataframe for modeling so it can be droppped here as well. You should  hold out your response variable(s) so that you can have their true values available for model performance review. Let's set `AdultWeekend` to the y variable as your response for scaling and modeling. Later, you will go back and consider the `AdultWeekday`, `dayOpenLastYear`, and `projectedDaysOpen`. For now leave them in the development dataframe. </font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove column Name from the dataframe\n",
    "df.drop('Name', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign Y to AdultWeekend and the rest of the dataframe to X\n",
    "Y = df['AdultWeekend']\n",
    "X = df.drop('AdultWeekend', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the scale of each features in X\n",
    "data = scale(X, axis=0, with_mean=True, with_std=True, copy=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GAT8h4_mZyGK"
   },
   "source": [
    "## Split into training and testing datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6rdS8EGeAnrW"
   },
   "source": [
    "**<font color='teal'> Using sklearn model selectionm import train_test_split, and create a 75/25 split with the y = `AdultWeekend`. You will start by using the adult weekend ticket price as your response variable for modeling.</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BSkPut0gguds"
   },
   "outputs": [],
   "source": [
    "# Create a 75/25 train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, Y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UayqbwkWAnra"
   },
   "source": [
    "Here, you'll start the actual modeling work. First let's fit a multiple linear regression model to predict the `AdultWeekend` price."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guided Capstone Step 5 - Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've cleaned and prepared the datasets, so now it's time to get into the most exciting part of this process: modeling! In this exercise, you will build three different models and compare each model's performance. In the end, you will choose the best model for proving insights to Big Mountain management.  \n",
    "\n",
    "1.   Problem Identification \n",
    "\n",
    "2.   Data Wrangling \n",
    "  \n",
    "3.   Exploratory Data Analysis \n",
    " \n",
    "4.   Pre-processing and Training Data Development\n",
    "\n",
    "5.   **Modeling**\n",
    "  * Fit Models with Training Data Set\n",
    "  * Review Model Outcomes — Iterate over additional models as needed.\n",
    "  * Identify the Final Model\n",
    "\n",
    "6.   Documentation\n",
    "  * Review the Results\n",
    "  * Present and share your findings - storytelling\n",
    "  * Finalize Code \n",
    "  * Finalize Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D_wfsP_-Anra"
   },
   "source": [
    "## Fit Models with Training Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CoI8S5SwAnrc"
   },
   "source": [
    "**<font color='teal'> Using sklearn, fit the model on your training dataset.</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P_GFr8sRAnrd"
   },
   "source": [
    "#### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fW6K7uOPAnre"
   },
   "outputs": [],
   "source": [
    "#all first model set\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import explained_variance_score,mean_absolute_error\n",
    "lm = linear_model.LinearRegression()\n",
    "model = lm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1fHqz9-WAnrg"
   },
   "source": [
    "**<font color='teal'> Predict on the testing dataset and score the model performance with the y_test set and the y-pred values. The explained variance is a measure of the variation explained by the model. This is also known as the R-squared value. </font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a prediction y_pred\n",
    "y_pred = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nIo01lFEAnrh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance Score (R-squared): 0.80\n",
      "Mean Absolute Error: 5.09\n"
     ]
    }
   ],
   "source": [
    "print('Explained Variance Score (R-squared): %.2f'\n",
    "      % explained_variance_score(y_test, y_pred))\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print('Mean Absolute Error: %.2f'\n",
    "      % mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N4YS0WE2Anrk"
   },
   "source": [
    "## Review Model Outcomes — Iterate over additional models as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HSh9sGIYAnrk"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61.07156049389448"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Intercept value from the linear model\n",
    "lm.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NWJcOuSdAnrr"
   },
   "source": [
    "**<font color='teal'> Print the intercept value from the linear model. </font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3WzWejn6Anrt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Coefficient\n",
      "total_chairs       2.756926e+12\n",
      "surface            1.002605e+12\n",
      "double             9.703812e+11\n",
      "fastQuads          9.563704e+11\n",
      "triple             8.700398e+11\n",
      "quad               6.874604e+11\n",
      "New York           6.309010e+11\n",
      "Michigan           5.836520e+11\n",
      "Pennsylvania       4.803653e+11\n",
      "Wisconsin          4.529635e+11\n",
      "New Hampshire      4.529635e+11\n",
      "Colorado           4.384418e+11\n",
      "California         4.384418e+11\n",
      "Vermont            4.232986e+11\n",
      "Minnesota          4.074646e+11\n",
      "Montana            3.908558e+11\n",
      "Massachusetts      3.908558e+11\n",
      "Idaho              3.548740e+11\n",
      "Washington         3.548740e+11\n",
      "Utah               3.352044e+11\n",
      "New Mexico         3.141394e+11\n",
      "Wyoming            3.141394e+11\n",
      "Oregon             3.141394e+11\n",
      "fastSixes          3.105575e+11\n",
      "Maine              2.913767e+11\n",
      "Ohio               2.664814e+11\n",
      "North Carolina     2.664814e+11\n",
      "Virginia           2.387876e+11\n",
      "West Virginia      2.387876e+11\n",
      "trams              2.375225e+11\n",
      "Iowa               2.071759e+11\n",
      "Illinois           2.071759e+11\n",
      "Connecticut        2.071759e+11\n",
      "Missouri           1.694680e+11\n",
      "South Dakota       1.694680e+11\n",
      "Indiana            1.694680e+11\n",
      "Arizona            1.694680e+11\n",
      "Alaska             1.694680e+11\n",
      "Nevada             1.694680e+11\n",
      "New Jersey         1.694680e+11\n",
      "Rhode Island       1.200504e+11\n",
      "Maryland           1.200504e+11\n",
      "Tennessee          1.200504e+11\n",
      "fastEight          3.181993e+10\n",
      "AdultWeekday       1.207715e+01\n",
      "vertical_drop      2.257779e+00\n",
      "Runs               1.445984e+00\n",
      "averageSnowfall    1.107544e+00\n",
      "projectedDaysOpen  1.063660e+00\n",
      "NightSkiing_ac     1.023926e+00\n",
      "SkiableTerrain_ac  1.015961e+00\n",
      "daysOpenLastYear   7.583694e-01\n",
      "kmean_cluster      6.979370e-01\n",
      "TerrainParks       4.917908e-01\n",
      "Snow Making_ac     3.872223e-01\n",
      "base_elev          3.689956e-01\n",
      "LongestRun_mi      2.770996e-01\n",
      "yearsOpen          1.937714e-01\n"
     ]
    }
   ],
   "source": [
    "# Sort and print coeff\n",
    "coeff_df = pd.DataFrame(abs(lm.coef_), X.columns, columns=['Coefficient'])\n",
    "print(coeff_df.sort_values(by=['Coefficient'], ascending=False))\n",
    "\n",
    "# The chairs columns made it to the top of my list. Is it because if Step 3 of my choice of replacing null value by zero or mean()?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "edajrenAAnrv"
   },
   "source": [
    "**<font color='teal'> The intercept is the mean `AdultWeekend` price for all the resorts given the other characteristics. The addition or subtraction of each of the coefficient values in the regression are numeric adjustments applied to the intercept to provide a particular observation's value for the `AdultWeekend` resulting value. Also, because you took the time to scale your x values in the training data, you can compare each of the coefficients for the features to determine the feature's importance. Print the coefficient values from the linear model and sort in descending order to identify the top ten most important features.</font>** \n",
    "\n",
    "Hint: make sure to review the absolute value of the coefficients, because the adjustment may be positive or negative, but what you are looking for is the magnitude of impact on your response variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass X_train & X_test as DataFrame and add columns names\n",
    "X_train_df = pd.DataFrame(X_train, columns=X.columns)\n",
    "X_test_df = pd.DataFrame(X_test, columns=X.columns)\n",
    "\n",
    "\n",
    "# Drop the states columns\n",
    "X_train = X_train_df.drop(X_train_df.iloc[:,23:], axis = 1, inplace = False)\n",
    "X_test = X_test_df.drop(X_test_df.iloc[:,23:], axis = 1, inplace = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result as not as good as model one as the location of the resort plays a big importance on the price."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BpdALMoAAnry"
   },
   "source": [
    "**<font color='teal'>You should see that the top ten important features are different states. However, the state is not something the managers at the Big Mountain Resort can do anything about. Given that you care more about actionable traits associated with ticket pricing, rebuild the model without the state features and compare the results. </font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-mHYA1BzAnrz"
   },
   "source": [
    "#### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pz1YXAdiAnr0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance Score (R-squared): 0.75\n",
      "Mean Absolute Error: 6.04\n"
     ]
    }
   ],
   "source": [
    "#model2\n",
    "model2 = lm2.fit(X_train,y_train)\n",
    "\n",
    "# Create a prediction y_pred\n",
    "y_pred2 = lm2.predict(X_test)\n",
    "\n",
    "print('Explained Variance Score (R-squared): %.2f'\n",
    "      % explained_variance_score(y_test, y_pred2))\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print('Mean Absolute Error: %.2f'\n",
    "      % mean_absolute_error(y_test, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nM1EGf16Anr2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Coefficient\n",
      "AdultWeekday         12.607115\n",
      "vertical_drop         2.705003\n",
      "SkiableTerrain_ac     1.781336\n",
      "projectedDaysOpen     1.503339\n",
      "trams                 1.440023\n",
      "daysOpenLastYear      1.349606\n",
      "quad                  1.274282\n",
      "NightSkiing_ac        1.243065\n",
      "kmean_cluster         1.183630\n",
      "base_elev             1.087776\n",
      "Runs                  0.977167\n",
      "triple                0.610132\n",
      "fastEight             0.556737\n",
      "LongestRun_mi         0.541001\n",
      "fastQuads             0.470281\n",
      "total_chairs          0.434284\n",
      "surface               0.431172\n",
      "averageSnowfall       0.329976\n",
      "Snow Making_ac        0.323251\n",
      "fastSixes             0.226599\n",
      "yearsOpen             0.200986\n",
      "double                0.064247\n",
      "TerrainParks          0.019837\n"
     ]
    }
   ],
   "source": [
    "# Sort and print coeff\n",
    "coeff_df = pd.DataFrame(abs(lm2.coef_), X_test.columns, columns=['Coefficient'])\n",
    "print(coeff_df.sort_values(by=['Coefficient'], ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JWjQLr3LAnr6"
   },
   "source": [
    "**<font color='teal'> When reviewing your new model coefficients, note that `summit_elev` is now in the number two spot. From a managerial perspective, this is also difficult to change and highly correlated with `base_elev` and `vertical_drop`.  This time rebuild the model without the state features and without the `summit_elev` and without `base_elev`and compare the results. </font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RXqvcn93Anr7"
   },
   "source": [
    "#### Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6eugnDNNAnr8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance Score (R-squared): 0.75\n",
      "Mean Absolute Error: 6.08\n"
     ]
    }
   ],
   "source": [
    "# summit_elev was removed in step3 when checking high correlation between 2 features.\n",
    "# Remove base_elev\n",
    "X_train = X_train.drop(['base_elev'], axis = 1)\n",
    "X_test = X_test.drop(['base_elev'], axis = 1)\n",
    "\n",
    "\n",
    "#model3 \n",
    "lm3 = linear_model.LinearRegression()\n",
    "model3 = lm3.fit(X_train,y_train)\n",
    "\n",
    "# Create a prediction y_pred\n",
    "y_pred3 = lm3.predict(X_test)\n",
    "\n",
    "print('Explained Variance Score (R-squared): %.2f'\n",
    "      % explained_variance_score(y_test, y_pred3))\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print('Mean Absolute Error: %.2f'\n",
    "      % mean_absolute_error(y_test, y_pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pq0pW7G9Anr_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Coefficient\n",
      "AdultWeekday         12.432872\n",
      "vertical_drop         2.904696\n",
      "kmean_cluster         1.833248\n",
      "SkiableTerrain_ac     1.688649\n",
      "NightSkiing_ac        1.467509\n",
      "quad                  1.322176\n",
      "trams                 1.312774\n",
      "projectedDaysOpen     1.304340\n",
      "daysOpenLastYear      1.136212\n",
      "Runs                  0.661099\n",
      "triple                0.562092\n",
      "LongestRun_mi         0.558136\n",
      "averageSnowfall       0.543042\n",
      "fastEight             0.525908\n",
      "total_chairs          0.465281\n",
      "fastQuads             0.402880\n",
      "surface               0.375624\n",
      "fastSixes             0.320867\n",
      "Snow Making_ac        0.218045\n",
      "yearsOpen             0.207519\n",
      "double                0.108164\n",
      "TerrainParks          0.036461\n"
     ]
    }
   ],
   "source": [
    "# Sort and print coeff\n",
    "coeff_df = pd.DataFrame(abs(lm3.coef_), X_test.columns, columns=['Coefficient'])\n",
    "print(coeff_df.sort_values(by=['Coefficient'], ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MJvQMns6AnsI"
   },
   "source": [
    "## Identify the Final Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LD7-3iLcAnsK"
   },
   "source": [
    "**<font color='teal'> Review the model performances in the table below and choose the best model for proving insights to Big Mountain management about what features are driving ski resort lift ticket prices. Type your choice in the final markdown cell. You will explain your selection during the next step of the guided casptone. </font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "La5S9fRPAnsK"
   },
   "source": [
    "| Model | Explained Variance| Mean Absolute Error|Features Dropped|\n",
    "| --- | --- | --- | --- |\n",
    "| Model 1. | 0.80 |5.09  |-|\n",
    "| Model 2. | 0.75|6.04 |'state'|\n",
    "| Model 3. | 0.75 |6.08 |'state','summit_elev','base_elev'|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T2c-zn7TAnsL"
   },
   "source": [
    "Model Selection:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CgC0eMBrAnsM"
   },
   "source": [
    "Regardless of the performance of the model I will choose model 3 because we want to define a new lift ticket price, regardless of the location and altitude of the resort."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "RtEspslPZyGY",
    "s0DokMkAZyGc",
    "2iuitnKcZyHS",
    "iAWQxougZyHW",
    "ThMTimlBZyHZ",
    "QwZ-LkjXZyHt",
    "srtXEA3N4-Y9",
    "ChVreJupZyIA",
    "zDgSSsq1ZyID",
    "I3GYKWfi5Llg",
    "pmMvrhbI-viE",
    "ZXDPkW3UZyIX",
    "Dnc_vHQLZyId",
    "daJxuJ-dZyIg",
    "mAQ-oHiPZyIn",
    "hnGOsp3mZyIp"
   ],
   "name": "GuidedCapstoneStep5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": "0",
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
